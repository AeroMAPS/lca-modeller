from typing import Dict, List
import warnings
import os
import dill
import lca_algebraic as lcalg
from lca_algebraic.helpers import Activity
import pandas as pd
from sympy.parsing.sympy_parser import parse_expr
import numpy as np
import concurrent.futures

USER_DB = 'Foreground DB'
DEFAULT_PROJECT = 'lcav_default_project'


class LCAProblemReduced:
    """
    Reduced LCA Problem.
    This reduced problem does not require EcoInvent and to setup a brightway/lca_algebraic project.
    It is generated by a full LCA problem (see LCAProblem class).
    The LCIA relies on previously compiled expressions of the impacts.
    """

    def __init__(self, load_from_file: str = None):
        self.model = None  # model
        self.methods = None  # LCIA methods
        self.lambdas = None  # Compiled expressions of impacts
        self.param_registry = None  # Parameters
        self.df_processes = None

        if load_from_file is not None:
            self._load(load_from_file)

    def _load(self, file_path: str):
        """
        Loads a pre-existing LCA problem.
        """
        if not file_path.endswith('.pickle'):
            file_path = file_path + '.pickle'
        with open(file_path, 'rb') as file:
            data = dill.load(file)
            self.__dict__.update(data)

        print(f"Loaded LCA problem from {file_path}.")

    def save(self, file_path: str):
        """
        Saves the LCA problem for future use.
        """
        if not self.lambdas:
            warnings.warn(
                "No symbolic expression registered in LCA problem.")
        if not file_path.endswith('.pickle'):
            file_path = file_path + '.pickle'
        dill.dump(self.__dict__, file=open(file_path, 'wb'))  # Export LCAProblemReduced instance
        print(f"LCA problem saved in {file_path}.")

    def compute_lcia(self, alpha=1, **params):  # TODO: add 'method' parameter to calculate only the provided method
        """
        Modified version of postMultiLCAAlgebric from lca_algebraic library.

        Parameters
        ----------
        **params : dictionary of parameters and their values for calculating the LCIA
        """

        param_length = lcalg.lca._compute_param_length(params)

        # Init output
        res = np.zeros((len(self.methods), param_length), float)

        # Check and expand enum params, add default values
        completed_params = completeParamValues(params, self.param_registry)  # , lambd_with_params.params)

        # Expand single params and transform them to np.array
        for key in completed_params.keys():
            val = completed_params[key]
            if not isinstance(val, list):
                val = list([val] * param_length)
            completed_params[key] = np.array(val, float)

        # Compute result on whole vectors of parameter samples at a time : lambdas use numpy for vector computation
        def process(args):
            imethod = args[0]
            lambd_with_params: lcalg.LambdaWithParamNames = args[1]
            value = alpha * lambd_with_params.compute(**completed_params)
            return (imethod, value)

        # Use multithread for that
        with concurrent.futures.ThreadPoolExecutor() as exec:
            for imethod, value in exec.map(process, enumerate(self.lambdas)):
                res[imethod, :] = value

        df = pd.DataFrame(res,
                          index=[lcalg.method_name(method) + "[%s]" % lcalg.base_utils._method_unit(method) for method
                                 in self.methods]).transpose()

        # Single params (not a list a param values) ? => give the single row the name of the model activity
        if df.shape[0] == 1:
            model_name = lcalg.lca._actName(self.model)
            df = df.rename(index={0: model_name})

        return df

    def list_processes(self):
        """
        Lists the processes and their exchanges.
        """
        return self.df_processes

    def list_lcia_functions(self):
        """
        Lists the symbolic expressions of the model for each impact method.
        """
        if self.lambdas is None:
            warnings.warn("No symbolic expressions found.")
        exprs = {method_name: self.lambdas[i] for i, method_name in enumerate(self.methods)}
        df = pd.DataFrame(exprs.values(),
                          index=pd.MultiIndex.from_tuples(exprs.keys()),
                          columns=['Symbolic expressions'])
        return df


class LCAProblem:
    """
    Base LCA Problem.
    """

    def __init__(self, load_from_file: str = None):
        self.project = DEFAULT_PROJECT  # Project name
        self.model = None  # LCA model
        self.methods = None  # LCIA methods
        self.lambdas = None  # Compiled expressions of impacts
        self.user_db_path = None  # path to foreground database with parameters

        if load_from_file is not None:
            self._load(load_from_file)

    def _load(self, file_path: str):
        """
        Loads a pre-existing LCA problem.
        """
        if not file_path.endswith('.pickle'):
            file_path = file_path + '.pickle'
        with open(file_path, 'rb') as file:
            data = dill.load(file)
            self.__dict__.update(data)

        # Setup project
        lcalg.initProject(self.project)

        # Reimport foreground database with parameters
        lcalg.import_db(USER_DB)

        # Cleaning up the whole foreground database would remove the processes from the imported db...
        lcalg.resetDb(USER_DB)
        # lcalg.setForeground(USER_DB)

        print(f"Loaded LCA problem from {file_path} and {self.user_db_path}.")

    def save(self, file_path: str):
        """
        Saves the LCA problem for future use.
        """
        if not self.lambdas:
            warnings.warn(
                "No symbolic expression registered in LCA problem.")
        if not file_path.endswith('.pickle'):
            file_path = file_path + '.pickle'
        self.user_db_path = os.path.splitext(file_path)[0] + '.bw2'  # Path(file_path).stem + '.bw2'
        lcalg.export_db(USER_DB, self.user_db_path)  # export foreground database with LCA parameters
        dill.dump(self.__dict__, file=open(file_path, 'wb'))  # Export LCAProblem instance
        print(f"LCA problem saved in {file_path} and {self.user_db_path}.")

    def compute_lcia(self, parameters: Dict, extract_activities: List[Activity] = None):
        """
        Computes the LCIA using the main LCA_algebraic function.
        First, symbolic expressions of the model for each impact are compiled.
        Then, the expressions are evaluated for the parameter values provided.

        :param parameters: dict of {parameters: value or list of values}
        :param extract_activities: Optionnal : list of foregound or background activities. If provided, the result only integrate their contribution.

        :return res: dataframe of calculated impacts for each method.
        """

        if extract_activities == [self.model]:
            extract_activities = None

        # LCIA calculation
        res = lcalg.multiLCAAlgebric(
            self.model,  # The model
            self.methods,  # Impact categories / methods

            # List of sub activities to consider
            extract_activities=extract_activities,

            # Parameters of the model
            **parameters
        )
        return res

    def _compile_lcia_functions(self, extract_activities: List[Activity] = None):
        """
        Computes symbolic expressions of the model for each impact assessment method
        as a function of background activities and parameters.

        :param extract_activities: list of processes. If provided, the result only integrate their contribution.
        """
        # Sub processes to consider for the LCIA (useful to calculate individual contributions)
        #if not isinstance(extract_activities, list):
        #    extract_activities = [extract_activities]
        if extract_activities == [self.model]:
            extract_activities = None

        with lcalg.params.DbContext(USER_DB):
            self.lambdas = lcalg.lca._preMultiLCAAlgebric(
                self.model,
                self.methods,
                extract_activities=extract_activities
            )

    def generate_reduced_problem(self, extract_activities: List[Activity] = None) -> LCAProblemReduced:
        """
        Generates a reduced LCA problem from the symbolic expressions of the LCIA.
        The reduced problem relies on the symbolic expressions rather than EcoInvent and brightway
        to calculate the impacts.

        :param extract_activities: list of processes. If provided, the result only integrate their contribution.
        """

        # Compile symbolic expressions
        self._compile_lcia_functions(extract_activities)

        # Save parameters registry
        with lcalg.DbContext(USER_DB):
            param_registry = {param.name: dict(
                group=param.group or "",
                name=param.name,
                label=param.get_label(),
                type=param.type,  # 'enum' if isinstance(param, lcalg.EnumParam) else 'float',
                values=param.values if param.type == 'enum' else None,
                default=param.default,
                min=param.min,
                max=param.max,
                std=getattr(param, "std", None),
                distrib=param.distrib,
                unit=param.unit,
                db=param.dbname or "[project]") for param in lcalg.params._param_registry().all()}

        # Create reduced problem
        reduced_problem = LCAProblemReduced()
        reduced_problem.model = self.model
        reduced_problem.methods = self.methods
        reduced_problem.lambdas = self.lambdas
        reduced_problem.param_registry = param_registry
        reduced_problem.df_processes = self.list_processes()

        return reduced_problem

    def list_lcia_functions(self):
        """
        Lists the symbolic expressions of the model for each impact method.
        """
        if self.lambdas is None:
            warnings.warn("No symbolic expressions found. Compiling LCIA functions...")
            self._compile_lcia_functions()
        exprs = {method_name: self.lambdas[i] for i, method_name in enumerate(self.methods)}
        df = pd.DataFrame(exprs.values(),
                          index=pd.MultiIndex.from_tuples(exprs.keys()),
                          columns=['Symbolic expressions'])
        return df

    def list_processes(self):
        """
        Traverses the tree of sub-activities (sub-processes) until background database is reached.
        """

        activities = []
        units = []
        locations = []
        parents = []
        exchanges = []
        levels = []
        dbs = []

        def _recursive_activities(act,
                                  activities, units, locations, parents, exchanges, levels, dbs,
                                  parent: str = "", exc: dict = None, level: int = 0):

            if exc is None:
                exc = {}
            name = act.as_dict()['name']
            unit = act.as_dict()['unit']
            loc = act.as_dict()['location']
            if loc != 'GLO':
                name += f' [{loc}]'
            exchange = _getAmountOrFormula(exc)
            db = act.as_dict()['database']

            # Uncomment to stop BEFORE reaching the first level of background activities
            # if db != USER_DB:  # to stop BEFORE reaching the first level of background activities
            #    return

            activities.append(name)
            units.append(unit)
            locations.append(loc)
            parents.append(parent)
            exchanges.append(exchange)
            levels.append(level)
            dbs.append(db)

            # Uncomment to stop AFTER reaching the first level of background activities
            if db != USER_DB:
                return

            for exc in act.technosphere():
                _recursive_activities(exc.input, activities, units, locations, parents, exchanges, levels, dbs,
                                      parent=name,
                                      exc=exc,
                                      level=level + 1)
            return

        def _getAmountOrFormula(ex):
            """ Return either a fixed float value or an expression for the amount of this exchange"""
            if 'formula' in ex:
                return parse_expr(ex['formula'])
            elif 'amount' in ex:
                return ex['amount']
            return ""

        _recursive_activities(self.model, activities, units, locations, parents, exchanges, levels, dbs)
        data = {'activity': activities,
                'unit': units,
                'location': locations,
                'level': levels,
                'database': dbs,
                'parent': parents,
                'exchange': exchanges}

        df = pd.DataFrame(data, index=activities)

        return df

    def list_methods(self):
        """
        Lists the methods declared in the LCA problem.
        """
        res = pd.DataFrame(self.methods)
        return res

    @staticmethod
    def list_parameters():
        """
        Lists the parameters defined in the LCA problem.
        """
        parameters = lcalg.list_parameters()
        return parameters

    @staticmethod
    def list_databases():
        """
        Lists the databases used in the LCA problem.
        """
        databases = lcalg.list_databases()
        return databases


def expandParams(param, value=None):
    """
    Modified version of expandParams from classes EnumParam and ParamDef from lca_algebraic library.
    For enum (switch) parameters, returns a dictionary of single enum values as sympy symbols,
    with only a single one set to 1.
    For float parameters, returns a dictionary with either the user-provided value or the default parameter value.
    """

    # Enum (e.g. switch) parameters
    if param['type'] == 'enum':
        values = param['values'] + [None]

        # Bad value ?
        if value not in values:
            raise Exception("Invalid value %s for param %s. Should be in %s" %
                            (value, param['name'], str(param['values'])))

        res = dict()
        for enum_val in values:
            var_name = "%s_%s" % (param['name'], enum_val if enum_val is not None else "default")
            res[var_name] = 1.0 if enum_val == value else 0.0
        return res

    # Float parameters
    else:
        if value is None:
            value = param['default']
        return {param['name']: value}


def completeParamValues(params, param_registry, setDefaults=True):
    """
    Modified version of completeParamValues from lca_algebraic library.
    Sets default values for missing parameters and expand enum params.

    Returns
    -------
        Dict of param_name => float value
    """

    # Set default variables for missing values
    if setDefaults:
        for name, param in param_registry.items():
            if not name in params:
                params[name] = param['default']
                lcalg.error(
                    "Required param '%s' was missing, replacing by default value : %s" % (name, str(param['default'])))

    res = dict()
    for key, val in params.items():
        if key in param_registry:
            param = param_registry[key]
        else:
            continue
            # raise Exception("Parameter not found : %s. Valid parameters : %s" % (key, list(param_registry.keys())))

        if isinstance(val, list):
            newvals = [expandParams(param, val) for val in val]
            res.update(lcalg.params._listOfDictToDictOflist(newvals))
        else:
            res.update(expandParams(param, val))

    return res

